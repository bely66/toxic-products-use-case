{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b80596",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d75d4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salla\\anaconda3\\envs\\sallaenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel,BertTokenizerFast, AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b818cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c99440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad00e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    sequencePattern   = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "    \n",
    "    #remove nan\n",
    "    text = re.sub('\\bnan\\b', '', text)\n",
    "    text = re.sub(r'\\b[nN][aA][nN]\\b', '', text)\n",
    "    # remove urls\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', ' ', text)\n",
    "    \n",
    "    #remove &nbsp;\n",
    "    text = re.sub('&nbsp;', ' ', text)\n",
    "    \n",
    "    # remove html tages\n",
    "    text = re.sub('<.*?>+', ' ', text)\n",
    "    \n",
    "    # Removing @user\n",
    "    text = re.sub(r'@[^\\s]+', ' ', text)\n",
    "    \n",
    "    # remove #word with word\n",
    "    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = re.sub('[%s]' % re.escape(punctuations_list), ' ', text)\n",
    "    \n",
    "    # remove new line\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    \n",
    "    # Removing multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Replace 3 or more consecutive letters by 2 letter.\n",
    "    text = re.sub(sequencePattern, seqReplacePattern, text)\n",
    "    \n",
    "    # Removing English words and numbers and make right strip\n",
    "    text = re.sub(r'\\s*[0-9]+\\b', '' , text).rstrip()\n",
    "    \n",
    "    # lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15798c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32a322dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text): \n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28f687a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(text):\n",
    "    \n",
    "    # Clean puntuation, urls, and so on\n",
    "    text = clean_text(text)\n",
    "    \n",
    "    # Normalize the text \n",
    "    text = normalize_arabic(text)\n",
    "\n",
    "    # Remove emojis\n",
    "    text = remove_emojis(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cbd97a",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "579e33cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train      = pd.read_csv(\"datasets/train_dataset/train_data_v3.csv\")\n",
    "validation = pd.read_csv(\"datasets/validation_dataset/validation_data_v3.csv\")\n",
    "test_1     = pd.read_csv(\"datasets/test_dataset/test_data_Nov_v1.csv\")\n",
    "test_2     = pd.read_csv(\"datasets/test_dataset/test_data_Dec_v1.csv\")\n",
    "test_3     = pd.read_csv(\"datasets/test_dataset/test_data_Nov_Dec_Oct_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34bc4a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'product_id', 'product_name', 'product_description',\n",
       "       'product_type', 'product_status', 'brand_name', 'brand_description',\n",
       "       'day', 'model_prediction', 'manual_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab8e3a",
   "metadata": {},
   "source": [
    "## Rename Columns in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "80d868dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = test_1.rename(columns={\"product_name_cleaned\":\"final_product_name\",\n",
    "                         \"product_description_cleaned\":\"final_product_description\"})\n",
    "\n",
    "test_2 = test_2.rename(columns={\"product_name\":\"final_product_name\",\n",
    "                         \"product_description\":\"final_product_description\"})\n",
    "\n",
    "test_2['manual_label'] = test_2['manual_label'].replace([2],[0]) # products need to confirm if they are toxic or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f7fe6918",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = pd.read_csv(\"datasets/train_dataset/all_train_data_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b780e912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65123, 23189, 2731, 1166, 80779, 117127)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(validation), len(test_1), len(test_2), len(test_3), len(all_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709857c5",
   "metadata": {},
   "source": [
    "# drop unnecessary columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "46c3f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "train          = train[['final_product_name', 'final_product_description', 'toxicity']]\n",
    "validation     = validation[['final_product_name', 'final_product_description', 'toxicity']]\n",
    "test_1         = test_1[['final_product_name', 'final_product_description', 'original_label']].rename(columns = {'original_label':'toxicity'})\n",
    "test_2         = test_2[['final_product_name', 'final_product_description', 'manual_label']].rename(columns = {'manual_label':'toxicity'})\n",
    "test_3         = test_3[['final_product_name', 'final_product_description', 'toxicity']]\n",
    "all_train_data = all_train_data[['final_product_name', 'final_product_description', 'toxicity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "deae5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 65123\n",
      "test 23189\n",
      "all_train 117127\n",
      "Nov 2731\n",
      "Dec 1166\n",
      "new Nov Dec 80779\n"
     ]
    }
   ],
   "source": [
    "print(\"train {}\".format(len(train)))        \n",
    "print(\"test {}\".format(len(validation)))                   \n",
    "print(\"all_train {}\".format(len(all_train_data)))          \n",
    "print(\"Nov {}\".format(len(test_1)))                      \n",
    "print(\"Dec {}\".format(len(test_2)))                      \n",
    "print(\"new Nov Dec {}\".format(len(test_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9218b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tag']           = \"train\"        \n",
    "validation['tag']      = \"validation\"         \n",
    "all_train_data['tag']  = \"all_train\"    \n",
    "test_1['tag']          = \"test_1\"      \n",
    "test_2['tag']          = \"test_2\"      \n",
    "test_3['tag']          = \"test_3\"      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ed5fce44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag\n",
      "all_train     117127\n",
      "test_3         80779\n",
      "train          65123\n",
      "validation     23189\n",
      "test_1          2731\n",
      "test_2          1166\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(290115,\n",
       " Index(['final_product_name', 'final_product_description', 'toxicity', 'tag'], dtype='object'))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([train, validation, all_train_data, test_1, test_2, test_3], ignore_index=True)\n",
    "print(data.tag.value_counts())\n",
    "len(data), data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5459ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of data 289999\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna(subset=['final_product_name'], how='all')\n",
    "print(\"size of data {}\".format(len(data)))\n",
    "data = data.reset_index(drop= True)\n",
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "58558822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "all_train     117069\n",
       "test_3         80779\n",
       "train          65065\n",
       "validation     23189\n",
       "test_1          2731\n",
       "test_2          1166\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7bb5533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['soup_of_text'] = [f\"{data['final_product_name'][i]} {data['final_product_description'][i]}\" for i in range(len(data))]\n",
    "\n",
    "data['soup_of_text_clean']  = data['soup_of_text'].apply(lambda q: preprocess_data(q))\n",
    "\n",
    "data['toxicity'] = data.toxicity.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "28db09c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag         toxicity\n",
       "all_train   0           75070\n",
       "            1           41999\n",
       "test_1      0            2122\n",
       "            1             609\n",
       "test_2      0             695\n",
       "            1             471\n",
       "test_3      0           48897\n",
       "            1           31882\n",
       "train       0           34751\n",
       "            1           30314\n",
       "validation  1           11681\n",
       "            0           11508\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['tag']).toxicity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "98ce61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data   = data[(data['tag'] == 'train')].reset_index(drop = True)\n",
    "val_data     = data[data['tag'] == 'validation'].reset_index(drop = True)\n",
    "all_train    = data[(data['tag'] == 'all_train')].reset_index(drop = True)\n",
    "test_1_data  = data[data['tag'] == 'test_1'].reset_index(drop = True)\n",
    "test_2_data  = data[data['tag'] == 'test_2'].reset_index(drop = True)\n",
    "test_3_data  = data[data['tag'] == 'test_3'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3131ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "06037b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65065, 23189, 2731, 1166, 80779)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data),len(val_data), len(test_1_data), len(test_2_data), len(test_3_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a13cc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts  = train_data['soup_of_text_clean']\n",
    "train_labels = train_data['toxicity']\n",
    "\n",
    "val_texts    = val_data['soup_of_text_clean']\n",
    "val_labels   = val_data['toxicity']\n",
    "\n",
    "all_train_texts  = all_train['soup_of_text_clean']\n",
    "all_train_labels = all_train['toxicity']\n",
    "\n",
    "test_1_text   = test_1_data['soup_of_text_clean']\n",
    "test_1_labels = test_1_data['toxicity']\n",
    "\n",
    "test_2_text   = test_2_data['soup_of_text_clean']\n",
    "test_2_labels = test_2_data['toxicity']\n",
    "\n",
    "test_3_text   = test_3_data['soup_of_text_clean']\n",
    "test_3_labels = test_3_data['toxicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c8a2daa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|███████████████| 499M/499M [00:11<00:00, 45.1MB/s]\n",
      "C:\\Users\\salla\\anaconda3\\envs\\sallaenv\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\salla\\.cache\\huggingface\\hub\\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL_NAME = 'roberta-base'\n",
    "bert = AutoModel.from_pretrained(BERT_MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(BERT_MODEL_NAME, num_labels=2)\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(BERT_MODEL_NAME, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10c79c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get length of all the messages in the train set\n",
    "#seq_len = [len(tokenizer.encode(i)) for i in train_texts]\n",
    "#pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "185e8fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7c856eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts.to_list(),\n",
    "                            truncation=True,\n",
    "                            padding=True,\n",
    "                            max_length=max_seq_len)\n",
    "\n",
    "val_encodings = tokenizer(val_texts.to_list(),\n",
    "                           truncation=True,\n",
    "                           padding=True,\n",
    "                           max_length=max_seq_len)\n",
    "\n",
    "all_encodings = tokenizer(all_train_texts.to_list(),\n",
    "                           truncation=True,\n",
    "                           padding=True,\n",
    "                           max_length=max_seq_len)\n",
    "\n",
    "test_1_encodings = tokenizer(test_1_text.to_list(),\n",
    "                           truncation=True,\n",
    "                           padding=True,\n",
    "                           max_length=max_seq_len)\n",
    "\n",
    "test_2_encodings = tokenizer(test_2_text.to_list(),\n",
    "                           truncation=True,\n",
    "                           padding=True,\n",
    "                           max_length=max_seq_len)\n",
    "\n",
    "test_3_encodings = tokenizer(test_3_text.to_list(),\n",
    "                           truncation=True,\n",
    "                           padding=True,\n",
    "                           max_length=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3ea20cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels.to_list()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0abb8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset     = TweetDataset(train_encodings, train_labels)\n",
    "val_dataset       = TweetDataset(val_encodings, val_labels)\n",
    "all_train_dataset = TweetDataset(all_encodings, all_train_labels)\n",
    "test_1_dataset    = TweetDataset(test_1_encodings, test_1_labels)\n",
    "test_2_dataset    = TweetDataset(test_2_encodings, test_2_labels)\n",
    "test_3_dataset    = TweetDataset(test_3_encodings, test_3_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b9315cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b1f1bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=20,\n",
    "    do_train=True,\n",
    "    do_eval=False,\n",
    "    per_device_train_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    learning_rate = 5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy='epoch'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "20bdfadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer1 = Trainer(\n",
    "    model=model1,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc22661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salla\\anaconda3\\envs\\sallaenv\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11660' max='40680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11660/40680 1:14:59 < 3:06:39, 2.59 it/s, Epoch 5.73/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2034</td>\n",
       "      <td>0.243400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4068</td>\n",
       "      <td>0.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6102</td>\n",
       "      <td>0.093700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8136</td>\n",
       "      <td>0.078100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10170</td>\n",
       "      <td>0.071900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores    = trainer1.predict(val_dataset)\n",
    "test_1_scores = trainer1.predict(test_1_dataset)\n",
    "test_2_scores = trainer1.predict(test_2_dataset)\n",
    "test_3_scores = trainer1.predict(test_3_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred    = np.argmax(val_scores[0], axis=1)\n",
    "test_1_pred = np.argmax(test_1_scores[0], axis=1)\n",
    "test_2_pred = np.argmax(test_2_scores[0], axis=1)\n",
    "test_3_pred = np.argmax(test_3_scores[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5705494",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'v{}_small_model_results'.format(VERSION)\n",
    "\n",
    "val_data[col]    = val_pred\n",
    "test_1_data[col] = test_1_pred\n",
    "test_2_data[col] = test_2_pred\n",
    "test_3_data[col] = test_3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc5be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"train over {}, and validate over {}\".format(len(train_dataset), len(val_dataset)))\n",
    "print(classification_report(test_label, val_pred))\n",
    "\n",
    "print(\"train over {}, and test over {} (NOV)\".format(len(train_dataset), len(test_1_dataset)))\n",
    "print(classification_report(nov_labels, test_1_pred ))\n",
    "\n",
    "print(\"train over {}, and test over {} (DEC)\".format(len(train_dataset), len(test_2_dataset)))\n",
    "print(classification_report(nov_labels, test_2_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a62d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train over {}, and test over {} (DEC)\".format(len(train_dataset), len(test_3_dataset)))\n",
    "print(classification_report(nov_labels, test_3_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer1.save_model('models/toxic_model_v{}_less'.format(VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44221317",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer2 = Trainer(\n",
    "    model=model2,\n",
    "    args=training_args,\n",
    "    train_dataset=all_train_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d4d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059287ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_scores_2 = trainer2.predict(test_1_dataset)\n",
    "test_2_scores_2 = trainer2.predict(test_2_dataset)\n",
    "test_3_scores_2 = trainer2.predict(test_3_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea94f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_pred_2 = np.argmax(test_1_scores_2[0], axis=1)\n",
    "test_2_pred_2 = np.argmax(test_2_scores_2[0], axis=1)\n",
    "test_3_pred_2 = np.argmax(test_3_scores_2[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"v{}_big_model_results\".format(VERSION)\n",
    "\n",
    "test_1_data[col] = test_1_pred_2\n",
    "test_2_data[col] = test_2_pred_2\n",
    "test_3_data[col] = test_3_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26effaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train over {}, and test over {} (NOV)\".format(len(all_train_dataset), len(test_1_dataset)))\n",
    "print(classification_report(nov_labels, test_1_pred_2))\n",
    "\n",
    "print(\"train over {}, and test over {} (DEC)\".format(len(all_train_dataset), len(test_2_dataset)))\n",
    "print(classification_report(dec_labels, test_2_pred_2 ))\n",
    "\n",
    "print(\"train over {}, and test over {} (DEC)\".format(len(all_train_dataset), len(test_3_dataset)))\n",
    "print(classification_report(dec_labels, test_2_pred_3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer2.save_model('models/toxic_model_v{}'.format(VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d98406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
